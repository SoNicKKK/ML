{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "<center> Автор материала: Павел Нестеров (@mephistopheies).\n",
    "\n",
    "Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watermark\n",
      "  Downloading watermark-1.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: ipython in c:\\users\\nryabykh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from watermark)\n",
      "Installing collected packages: watermark\n",
      "Successfully installed watermark-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.5.2\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.13.1\n",
      "scipy 0.19.1\n",
      "pandas 0.22.0\n",
      "matplotlib 2.0.2\n",
      "sklearn 0.19.0\n",
      "\n",
      "compiler   : MSC v.1900 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 7\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 69 Stepping 1, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : 30c6e3676666b8081b4485e7c08fdd960eff1c19\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'java', 'python', 'html', 'c#', 'php', 'javascript', 'android', 'c++', 'jquery', 'ios'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) &=& \\dfrac{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} = \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\textbf{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\textbf{x}\\right) &=& \\dfrac{p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\textbf{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} = \\sigma_k\\left(\\textbf{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\textbf{x}, y}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\textbf{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\textbf{z}\\right)\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\textbf{z}\\right)\\right)\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\textbf{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\textbf{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответ\n",
    "\n",
    "Видимо, правильный ответ -- №2. В формуле выше сигма зависит от суммы по всем признакам, эта сумма считается отдельно для каждого класса (т.к. мы обучаем модели отдельно для каждого класса). Значит, если сигма будет под суммой, то суммирование должно вестись по всем классам. Значит, остаются варианты 2 или 3. Сигма считается от аргумента $z_k$ --- значит, правильный ответ 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font> В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -n 1000 ../../data/stackoverflow_sample_125k.tsv > ../../data/test1000.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:     \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    #z = self._b[tag]\n",
    "                    z = 0\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "                        \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if z > 0:\n",
    "                        ex = np.exp(-z)\n",
    "                        sigma = 1 / (1 + ex)\n",
    "                    else:\n",
    "                        ex = np.exp(z)\n",
    "                        sigma = ex / (1 + ex)\n",
    "                        \n",
    "                    sigma = tolerance if sigma < tolerance else sigma\n",
    "                    sigma = 1 - tolerance if sigma > 1 - tolerance else sigma\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss -= y * np.log(sigma) + (1-y) * np.log(1-sigma)\n",
    "                    #print(sample_loss)\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = (y - sigma)\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "#!head -n 10000 ../../data/stackoverflow_sample_125k.tsv > ../../data/test.tsv\n",
    "model = LogRegressor()\n",
    "#model.iterate_file(fname='../../data/test.tsv', total=10000)\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1868cfd0>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2UAAAEuCAYAAAAOdrrVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc58cd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(window=10000).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 19.90\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. **19.74**\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(\\textbf W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
