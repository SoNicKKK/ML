{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом блокноте приведены решения задач к третьему уроку по курсу ВШЭ \"Эконометрика\" на [coursera](https://www.coursera.org/learn/ekonometrika/home/week/3). Темы урока: вычисление вариаций для прогнозов регрессии, дамми-переменные, сравнение ограниченных и неограниченных моделей, проверка на лишние и недостающие регрессоры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача на нахождение вариации для среднего и для прогноза\n",
    "\n",
    "**Задача**\n",
    "\n",
    "По 2040 наблюдениям оценена модель зависимости стоимости цены квартиры $price_i$ (в 1000) от метража жилой площади $livesp_i$: $price_i=−90+1.8livesp_i$. При построении 95% доверительного интервала для $E\\left(price_f\\mid livesp=70\\right)$, чему равна $\\hat{Var}\\left(\\hat{price_f}\\mid X\\right)$, eсли $\\sigma^2=1259.265$, а ковариационная матрица имеет следующий вид: $\\hat{Var}\\left(\\hat{\\beta}\\mid X\\right)=\\begin{pmatrix}21.9 & -0.46 \\\\ -0.46 & 0.01 \\end{pmatrix}$.\n",
    "\n",
    "Чему равна $\\hat(Var(price_f - \\hat{price_f}\\mid X)?\n",
    "\n",
    "**Решение**\n",
    "\n",
    "Для значения регрессора $livesp = 70$ получаем такую модель регрессии: $price=\\beta_1 + \\beta_2 \\cdot 70$. По формулам для вариации суммы величин получаем: $\\hat{Var}(\\hat{price}) = Var(\\beta_1) + 70^2 \\cdot Var(\\beta_2) + 2\\cdot 70 \\cdot cov(\\beta_1 \\beta_2) = 6.5$\n",
    "\n",
    "$\\hat{Var}(price_f - \\hat{price_f}\\mid X)$ - это вариация для цены случайной квартиры, она на $\\sigma^2$ больше, чем вариация для среднего значения цены: $\\hat{Var}(price_f - \\hat{price_f}\\mid X) = 6.5 + 1259.265 = 1265.675$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.5, 1265.765)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = 1259.265\n",
    "var1 = 21.9\n",
    "var2 = 0.01\n",
    "cov12 = -0.46\n",
    "l = 70\n",
    "var_y_mean = var1 + l**2 * var2 + 2*l*cov12\n",
    "var_y_pred = sigma + var1 + 70**2 * var2 + 2*70*cov12\n",
    "round(var_y_mean, 2), round(var_y_pred, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бриллианты\n",
    "\n",
    "Загружаем данные по бриллиантам (датасет `diamonds` из R)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "1   0.23    Ideal     E     SI2   61.5     55    326  3.95  3.98  2.43\n",
       "2   0.21  Premium     E     SI1   59.8     61    326  3.89  3.84  2.31\n",
       "3   0.23     Good     E     VS1   56.9     65    327  4.05  4.07  2.31\n",
       "4   0.29  Premium     I     VS2   62.4     58    334  4.20  4.23  2.63\n",
       "5   0.31     Good     J     SI2   63.3     58    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diamonds.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 53940)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns), len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простая оценка модели\n",
    "\n",
    "**Задача**\n",
    "\n",
    "Оцените модель $price_i=\\beta_1 + \\beta_2 \\log(carat_i)+\\epsilon_i$. С ростом количества карат на 1% на сколько долларов растёт цена?\n",
    "\n",
    "**Решение**\n",
    "\n",
    "Для составления моделей используем пакет `statsmodels`, необходимые функции см. ниже. По умолчанию в регрессию не входит константа, поэтому в функцию `OLS` надо передавать не просто столбцы с признаками, а результат функции `statsmodels.api.add_constant`, которая добавляет к матрице признаков столбец из единиц.\n",
    "\n",
    "Поскольку в качестве регрессора используется логарифм числа карат, то для ответа на вопрос задачи надо узнать коэффициент при этом регрессоре и разделить его на 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.732\n",
      "Model:                            OLS   Adj. R-squared:                  0.732\n",
      "Method:                 Least Squares   F-statistic:                 1.473e+05\n",
      "Date:                Sat, 13 Aug 2016   Prob (F-statistic):               0.00\n",
      "Time:                        21:43:10   Log-Likelihood:            -4.8827e+05\n",
      "No. Observations:               53940   AIC:                         9.765e+05\n",
      "Df Residuals:                   53938   BIC:                         9.766e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const       6237.8366     10.732    581.228      0.000      6216.802  6258.872\n",
      "carat       5836.0246     15.208    383.753      0.000      5806.217  5865.832\n",
      "==============================================================================\n",
      "Omnibus:                    12687.973   Durbin-Watson:                   0.249\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31397.193\n",
      "Skew:                           1.298   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.688   Cond. No.                         2.08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "model = sm.OLS(df.price, sm.add_constant(df.carat.apply(np.log)))\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка гипотезы о значимости регрессии\n",
    "\n",
    "**Задача**\n",
    "\n",
    "Оцените модель $price_i=\\beta_1+\\beta_2 carat_i+\\beta_3 x_i+\\epsilon_i$. Проверьте гипотезу о значимости регрессии в целом на уровне значимости 1%.\n",
    "\n",
    "**Решение**\n",
    "\n",
    "Гипотеза о значимости регрессии проверяется F-тестом. Если значение F-статистики большое, то нулевая гипотеза (о том, что все коэффициенты равны 0) отвергается. Также можно посмотреть p-значения при отдельных коэффициентах: если их значения меньше, чем уровень значимости (0.01), то они являются значимыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.853\n",
      "Model:                            OLS   Adj. R-squared:                  0.853\n",
      "Method:                 Least Squares   F-statistic:                 1.570e+05\n",
      "Date:                Sat, 13 Aug 2016   Prob (F-statistic):               0.00\n",
      "Time:                        21:43:13   Log-Likelihood:            -4.7199e+05\n",
      "No. Observations:               53940   AIC:                         9.440e+05\n",
      "Df Residuals:                   53937   BIC:                         9.440e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const       1737.9497    103.623     16.772      0.000      1534.848  1941.051\n",
      "carat       1.013e+04     62.554    161.875      0.000         1e+04  1.02e+04\n",
      "x          -1026.8569     26.433    -38.848      0.000     -1078.666  -975.048\n",
      "==============================================================================\n",
      "Omnibus:                    14013.447   Durbin-Watson:                   1.186\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           317502.525\n",
      "Skew:                           0.717   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.799   Cond. No.                         112.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "  results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нахождение других параметров модели\n",
    "\n",
    "**Задача**\n",
    "\n",
    "Чему равен скорректированный $R^2_adj$ в модели $price_i=\\beta_1+\\beta_2 carat_i+\\epsilon_i$?\n",
    "\n",
    "Оцените следующую модель: $price_i=\\beta_1+\\beta_2 carat_i+\\epsilon_i$. Чему равен AIC\n",
    "\n",
    "**Решение**\n",
    "\n",
    "Все нужные параметры можно посмотреть в `summary` результатов оценки. Также эти значения лежат в `model.fit()`, их можно посмотреть просто через точку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 adj = 0.85, AIC = 945464.53\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.849\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                 3.041e+05\n",
      "Date:                Sat, 13 Aug 2016   Prob (F-statistic):               0.00\n",
      "Time:                        21:43:16   Log-Likelihood:            -4.7273e+05\n",
      "No. Observations:               53940   AIC:                         9.455e+05\n",
      "Df Residuals:                   53938   BIC:                         9.455e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const      -2256.3606     13.055   -172.830      0.000     -2281.949 -2230.772\n",
      "carat       7756.4256     14.067    551.408      0.000      7728.855  7783.996\n",
      "==============================================================================\n",
      "Omnibus:                    14025.341   Durbin-Watson:                   0.986\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           153030.525\n",
      "Skew:                           0.939   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.035   Cond. No.                         3.65\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(df.price, sm.add_constant(df.carat))\n",
    "results = model.fit()\n",
    "print('R2 adj = %.2f, AIC = %.2f' % (results.rsquared_adj, results.aic))\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение нескольких моделей\n",
    "\n",
    "**Задача**\n",
    "\n",
    "Оцените следующие три модели на данных по бриллиантам:\n",
    "$$price_i=\\beta_1+\\beta_2 carat_i+\\epsilon_i$$,\n",
    "$$price_i=\\beta_1+\\beta_2 carat_i+\\beta_3 depth_i + \\epsilon_i$$,\n",
    "$$price_i=\\beta_1+\\beta_2 carat_i+\\beta_3 depth_i + \\beta_4 cut_i + \\epsilon_i$$\n",
    "\n",
    "Какая модель лучше по критерию AIC?\n",
    "\n",
    "**Решение**\n",
    "\n",
    "Главная проблема в том, что признак `cut` (огранка бриллианта) - категориальный, его надо факторизовать. Для этого надо ввести дамми-переменные. Это можно сделать средствами `pandas` функцией `pandas.get_dummies`. Она вернет 5 столбцов (по количеству разных значений в факторизуемом столбце) с нулями и единицами. Чтобы избежать мультиколлинеарности (линейной зависимости признаков), на вход модели подаем не 5 столбцов, а только 4 (в примере ниже убран столбец `Fair`).\n",
    "\n",
    "Второй вариант. Можно использовать модуль `statsmodels.formula.api`, в котором можно задавать регрессию формулой (синтаксис похож на R). Тогда можно не делать факторизацию вручную, а просто указать в формуле, что данная переменная - категориальная. При оценке одна из дамми-переменных будет исключена из регрессии автоматически. Другие примеры использования этого модуля можно найти [здесь](http://statsmodels.sourceforge.net/devel/example_formulas.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.join(pd.get_dummies(df.cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC1 = 945464, AIC2 = 944982, AIC3 = 942746\n"
     ]
    }
   ],
   "source": [
    "cols = list(df.cut.unique())\n",
    "model1 = sm.OLS(df.price, sm.add_constant(df[['carat']]))\n",
    "model2 = sm.OLS(df.price, sm.add_constant(df[['carat', 'depth']]))\n",
    "model3 = sm.OLS(df.price, sm.add_constant(df[['carat', 'depth'] + cols[:-1]]))\n",
    "res1 = model1.fit()\n",
    "res2 = model2.fit()\n",
    "res3 = model3.fit()\n",
    "print('AIC1 = %d, AIC2 = %d, AIC3 = %d' % (res1.aic, res2.aic, res3.aic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC =  942746.145422\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.857\n",
      "Model:                            OLS   Adj. R-squared:                  0.857\n",
      "Method:                 Least Squares   F-statistic:                 5.377e+04\n",
      "Date:                Sat, 13 Aug 2016   Prob (F-statistic):               0.00\n",
      "Time:                        21:55:46   Log-Likelihood:            -4.7137e+05\n",
      "No. Observations:               53940   AIC:                         9.427e+05\n",
      "Df Residuals:                   53933   BIC:                         9.428e+05\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept            -648.9073    312.841     -2.074      0.038     -1262.078   -35.737\n",
      "C(cut)[T.Good]       1036.2688     44.201     23.444      0.000       949.634  1122.904\n",
      "C(cut)[T.Ideal]      1684.0799     40.879     41.196      0.000      1603.956  1764.204\n",
      "C(cut)[T.Premium]    1299.4012     42.029     30.917      0.000      1217.024  1381.779\n",
      "C(cut)[T.Very Good]  1398.5562     41.607     33.613      0.000      1317.006  1480.106\n",
      "carat                7873.2487     13.967    563.691      0.000      7845.873  7900.625\n",
      "depth                 -50.4176      4.848    -10.401      0.000       -59.919   -40.916\n",
      "==============================================================================\n",
      "Omnibus:                    14603.603   Durbin-Watson:                   1.027\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           149669.122\n",
      "Skew:                           1.008   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.907   Cond. No.                     2.99e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.99e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sfm\n",
    "model3_f = sfm.ols('price ~ carat + depth + C(cut)', data=df)\n",
    "res3_f = model3_f.fit()\n",
    "print('AIC = ', res3_f.aic)\n",
    "print(res3_f.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка гипотезы о незначимости регрессоров (об ограничениях)\n",
    "\n",
    "**Задача**\n",
    "\n",
    "Оцените следующие две модели:\n",
    "$$price_i=\\beta_1+\\beta_2 carat_i+\\epsilon_i$$,\n",
    "$$price_i=\\beta_1+\\beta_2 carat_i+\\beta_3 depth_i+\\beta_4 cut_i+\\epsilon_i$$.\n",
    "\n",
    "Проведите тест на два линейных ограничения в R. Чему равно F-значение?\n",
    "\n",
    "**Решение**\n",
    "\n",
    "Надо оценить, имеет ли смысл вводить дополнительные переменные в регрессию или же можно обойтись и меньшим числом переменных без особой потери в качестве. Для этого проводится F-тест: считается значение F-статистики по формуле\n",
    "$$F = \\frac{\\left(R^2_{UR}-R^2_R\\right)/r}{\\left(1 - R^2_{UR}\\right) / (n-k)}$$, где $r$ - количество переменных, незначимость которых мы проверяем (количество ограничений), $n$ - количество наблюдений, $k$ - количество коэффициентов в неограниченной модели. Индексы UR относятся к неограниченной модели (с большим числом регрессоров), индексы $R$ - к ограниченной модели. Если значение этой статистики большое (больше F-критического при нужном уровне значимости), то нулевая гипотеза о том, что коэффициенты при этих регрессорах равны 0 отвергается.\n",
    "\n",
    "Значение F можно посчитать вручную, а можно воспользоваться функциями `wald_test` или `f_test` от результатов оценки. В качестве параметра туда надо передать матрицу: число строк равно числу ограничений, число столбцов равно числу коэффициентов в неограниченной модели, в самих строках на месте проверяемого коэффициента стоит 1, на остальных местах - 0. Вид матрицы приведен отдельно ниже. \n",
    "\n",
    "При решении надо учесть, что для регрессора `cut` создано 4 дамми-переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559.641097328\n"
     ]
    }
   ],
   "source": [
    "r_ur = res3.rsquared\n",
    "r_r = res1.rsquared\n",
    "r = 5\n",
    "n = len(df.index)\n",
    "k = 7\n",
    "print(((r_ur - r_r) / r) / ((1 - r_ur) / (n - k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const        -648.907301\n",
      "carat        7873.248664\n",
      "depth         -50.417619\n",
      "Ideal        1684.079947\n",
      "Premium      1299.401230\n",
      "Good         1036.268784\n",
      "Very Good    1398.556215\n",
      "dtype: float64\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]]\n",
      "<F test: F=array([[ 559.64109733]]), p=0.0, df_denom=53933, df_num=5>\n",
      "<F test: F=array([[ 559.64109733]]), p=0.0, df_denom=53933, df_num=5>\n"
     ]
    }
   ],
   "source": [
    "print(res3.params)\n",
    "print(np.eye(len(res3.params))[2:])\n",
    "print(res3.wald_test(np.eye(len(res3.params))[2:]))\n",
    "print(res3.f_test(np.eye(len(res3.params))[2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка пропуска переменнных (тест Рамсея)\n",
    "\n",
    "**Задача**\n",
    "\n",
    "Если провести тест Рамсея для модели $price_i=\\beta_1+\\beta_2 carat_i+\\beta_3 depth_i+\\beta_4 cut_i+\\epsilon_i$ на уровне значимости 1%, что он покажет?\n",
    "\n",
    "**Решение**\n",
    "\n",
    "Тест Рамсея проверяет, не пропущены ли какие-то переменные при построении регрессии (иными словами, достаточно ли имеющихся переменных для качественного описания или чего-то не хватает). Идея этого теста в следующем. Если для описания искомой переменной нам не хватает регрессоров, то часть необъясненной информации осталась в искомой переменной $y$. Значит, если мы добавим в регрессию новые слагаемые, которые являются степенями $y$, то качество регрессии должно увеличиться. Значит, можно сделать новую модель, в которую добавить, например, регрессоры $y^2$ и $y^3$, а затем проверить гипотезу о незначимости этих регрессоров. Если эта гипотеза отвергнута, значит, в исходной регрессии переменных недостаточно.\n",
    "\n",
    "**Я не нашел готовую функцию в `statsmodels`, которая осуществляет тест Рамсея (другое название - RESET-тест)**. Поэтому вручную добавим в модель регрессоры $y^2$ и $y^3$, а затем проведем `wald_test`. Если в результате теста получится довольно большое значение F-статистики (критическое значение на 95% уровне значимости - примерно 3), то нулевая гипотеза отвергается и регрессоров недостаточно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['price2'] = df.price ** 2\n",
    "df['price3'] = df.price ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model4 = sm.OLS(df.price, sm.add_constant(df[['carat', 'depth'] + cols[:-1] + ['price2', 'price3']]))\n",
    "res4 = model4.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=array([[ 318541.30937788]]), p=0.0, df_denom=53931, df_num=2>\n"
     ]
    }
   ],
   "source": [
    "print(res4.wald_test(np.eye(len(res4.params))[-2:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
